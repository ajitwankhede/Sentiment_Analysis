{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9155a8a5",
   "metadata": {},
   "source": [
    "Dataset:\n",
    "    \n",
    "    The label ‘1’ means the tweet is discriminatory / gender and the label ‘0’ means the tweet is not racist/sexist, you intend to predict the labels on the test data provided.\n",
    "    \n",
    "    The columns present in our dataset are :\n",
    "\n",
    "    1. id: unique id of the tweet\n",
    "\n",
    "    2.label : 0 or 1 (positive and negative)\n",
    "\n",
    "    3. tweet: text of the tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bb69a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installatin library\n",
    "# !pip3 install transformers\n",
    "# !pip3 install tensorflow\n",
    "# !pip3 install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6f7a308",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajitw\\anaconda3\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import DistilBertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import matplotlib as plot\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "064f67e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "train =pd.read_csv(\"train_2kmZucJ.csv\")\n",
    "test =pd.read_csv(\"test_oJQbWVk.csv\")\n",
    "ss =pd.read_csv(\"sample_submission_LnhVWA4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aff68b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>#fingerprint #Pregnancy Test https://goo.gl/h1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Finally a transparant silicon case ^^ Thanks t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>We love this! Would you go? #talk #makememorie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>I'm wired I know I'm George I was made that wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>What amazing service! Apple won't even talk to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0  #fingerprint #Pregnancy Test https://goo.gl/h1...\n",
       "1   2      0  Finally a transparant silicon case ^^ Thanks t...\n",
       "2   3      0  We love this! Would you go? #talk #makememorie...\n",
       "3   4      0  I'm wired I know I'm George I was made that wa...\n",
       "4   5      1  What amazing service! Apple won't even talk to..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca5e3c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7921</td>\n",
       "      <td>I hate the new #iphone upgrade. Won't let me d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7922</td>\n",
       "      <td>currently shitting my fucking pants. #apple #i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7923</td>\n",
       "      <td>I'd like to puts some CD-ROMS on my iPad, is t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7924</td>\n",
       "      <td>My ipod is officially dead. I lost all my pict...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7925</td>\n",
       "      <td>Been fighting iTunes all night! I only want th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                              tweet\n",
       "0  7921  I hate the new #iphone upgrade. Won't let me d...\n",
       "1  7922  currently shitting my fucking pants. #apple #i...\n",
       "2  7923  I'd like to puts some CD-ROMS on my iPad, is t...\n",
       "3  7924  My ipod is officially dead. I lost all my pict...\n",
       "4  7925  Been fighting iTunes all night! I only want th..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "549f0920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7921</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7922</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7923</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7924</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7925</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  label\n",
       "0  7921      0\n",
       "1  7922      0\n",
       "2  7923      0\n",
       "3  7924      0\n",
       "4  7925      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2242951",
   "metadata": {},
   "source": [
    "We are only interested in the column label and tweet. Tweet being input column ‘and label is the output variable. The label contains 0 and 1 . with 0 being the positive tweet and 1 being the negative tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ad2516c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping id as it is not of use\n",
    "train.drop(\"id\", axis = 1, inplace = True)\n",
    "test.drop(\"id\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "271d7295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>#fingerprint #Pregnancy Test https://goo.gl/h1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Finally a transparant silicon case ^^ Thanks t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>We love this! Would you go? #talk #makememorie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>I'm wired I know I'm George I was made that wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>What amazing service! Apple won't even talk to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              tweet\n",
       "0      0  #fingerprint #Pregnancy Test https://goo.gl/h1...\n",
       "1      0  Finally a transparant silicon case ^^ Thanks t...\n",
       "2      0  We love this! Would you go? #talk #makememorie...\n",
       "3      0  I'm wired I know I'm George I was made that wa...\n",
       "4      1  What amazing service! Apple won't even talk to..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a82ea43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I hate the new #iphone upgrade. Won't let me d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>currently shitting my fucking pants. #apple #i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'd like to puts some CD-ROMS on my iPad, is t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My ipod is officially dead. I lost all my pict...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Been fighting iTunes all night! I only want th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet\n",
       "0  I hate the new #iphone upgrade. Won't let me d...\n",
       "1  currently shitting my fucking pants. #apple #i...\n",
       "2  I'd like to puts some CD-ROMS on my iPad, is t...\n",
       "3  My ipod is officially dead. I lost all my pict...\n",
       "4  Been fighting iTunes all night! I only want th..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fe65594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution fo positive and negative labels in the data\n",
    "\n",
    "# Plotting the distribution fro dataset\n",
    "ax = train.groupby('label').count().plot(kind = 'bar', title= \"Distribution of data\", legend = False)\n",
    "ax.set_xticklabels(['Negative','Positive'], rotation=0)\n",
    "# sorting data in list\n",
    "text, sentiment = list(train['tweet']), list(train['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea0ee6a",
   "metadata": {},
   "source": [
    "Need to convert the tweet and labels column in the form of a list so that we can input them to the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bc1fcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting labels and tweet to list\n",
    "labels = train['label'].tolist()\n",
    "tweets = train['tweet'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee785ed8",
   "metadata": {},
   "source": [
    "Tokenization and Encoding of data:\n",
    "\n",
    "The tokenizer that we will be using is DistillBert tokenizer fast. DistilBertTokenizerFast is identical to BertTokenizerFast and runs end-to-end tokenization: punctuation splitting and wordpiece.\n",
    "\n",
    "The parameters that are present in DistilBertTokenizerFast are :\n",
    "\n",
    "( vocab_filedo_lower_case = Truedo_basic_tokenize = Truenever_split = Noneunk_token = ‘[UNK]’sep_token = ‘[SEP]’pad_token = ‘[PAD]’cls_token = ‘[CLS]’mask_token = ‘[MASK]’tokenize_chinese_chars = Truestrip_accents = None**kwargs )\n",
    "\n",
    "The method splits the sentences into tokens, adds the [cls] and [sep] tokens, and also matches the tokens to id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58f26172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization and Encoding of data\n",
    "from transformers import DistilBertTokenizerFast\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf10fdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#padding and truncation of data\n",
    "inputs = tokenizer(tweets, padding =\"max_length\", truncation = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258d2e85",
   "metadata": {},
   "source": [
    "So in tokenizer, we will give a list of tweets as the input and will get the token ids in return that we will input in the model.\n",
    "\n",
    "Padding, Truncation, and all of the preprocessing are done in the DistillBert tokenizer itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac91b104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert our data to tensors.\n",
    "import torch\n",
    "class twitterDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e68b9d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = twitterDataset(inputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00193cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    The output of this is a dictionary containing 3 key-value pair\\n\\n    Input id’s: This contains tensors of integers where each integer represents the word from the original sentence.\\n\\n    Attention Mask: It is simply an array of 1’s and 0’s indicating which tokens are padding and which aren’t.\\n\\n    Labels: target variables\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(train_dataset.__getitem__(2))\n",
    "\n",
    "'''\n",
    "    The output of this is a dictionary containing 3 key-value pair\n",
    "\n",
    "    Input id’s: This contains tensors of integers where each integer represents the word from the original sentence.\n",
    "\n",
    "    Attention Mask: It is simply an array of 1’s and 0’s indicating which tokens are padding and which aren’t.\n",
    "\n",
    "    Labels: target variables\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f751364e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Model Building\n",
    "# model : Distillbert model\n",
    "from transformers import DistilBertForSequenceClassification\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71b2fc38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06a434c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:1\")\n",
    "# device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2d8bd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install pytorch torchvision torchaudio pytorch-cuda=11.6 -c pytorch -c nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "afe6f1cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enalable gpu if it available\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cuda\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "308cae0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir ='./results',\n",
    "    num_train_epochs =2,\n",
    "    per_device_eval_batch_size =64,\n",
    "    warmup_steps = 500,\n",
    "    weight_decay = 0.01,\n",
    "    logging_dir ='./logs',\n",
    "    logging_steps = 10\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args= training_args,\n",
    "    train_dataset= train_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0668274",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajitw\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1980' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1980/1980 25:54, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.713900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.703100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.676000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.622500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.577800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.538000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.440800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.399600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.329200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.385400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.273100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.287700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.390600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.284300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.486300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.289200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.309100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.303500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.199900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.244800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.337800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.192400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.295300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.283600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.197800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.132600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.145100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.354200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.331300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.111700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.371400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.214200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.473800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.183700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.318600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.450700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.323100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.269300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.283900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.256800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.197400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.211800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.290800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.168300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.238600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.337300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.150100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.222600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.307000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.360800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.221300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.226800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.428800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.341100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.227500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.286700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.202200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.252000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.261800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.337800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>0.228400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.078500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.217900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.207800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.460300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.362900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>0.444700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.276300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.373600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.235800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>0.230500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.299800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>0.378400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.173300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.274000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.280800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>0.188400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.459600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>0.211100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.120700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>0.261600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>0.202000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>0.216500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.307600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.154700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.250600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>0.245600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.405400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>0.308600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.353700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>0.340600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>0.289700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>0.154600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>0.210400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.265600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.246300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>0.256200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>0.148900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>0.177000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.182500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010</td>\n",
       "      <td>0.281500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.068300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1030</td>\n",
       "      <td>0.301100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>0.098800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.283300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>0.325900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1070</td>\n",
       "      <td>0.225100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.189600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1090</td>\n",
       "      <td>0.185200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.268500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1110</td>\n",
       "      <td>0.182800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>0.133200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1130</td>\n",
       "      <td>0.261300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.203200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.282500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>0.075400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1170</td>\n",
       "      <td>0.044800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>0.112400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1190</td>\n",
       "      <td>0.206300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.059800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1210</td>\n",
       "      <td>0.294900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>0.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1230</td>\n",
       "      <td>0.261800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>0.135900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.217700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.194500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1270</td>\n",
       "      <td>0.214700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>0.250100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1290</td>\n",
       "      <td>0.178000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.192400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1310</td>\n",
       "      <td>0.174300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.234600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1330</td>\n",
       "      <td>0.248200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1340</td>\n",
       "      <td>0.190100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.159400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1360</td>\n",
       "      <td>0.264700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1370</td>\n",
       "      <td>0.256900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.204300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1390</td>\n",
       "      <td>0.172500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.110100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1410</td>\n",
       "      <td>0.339400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1420</td>\n",
       "      <td>0.193300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1430</td>\n",
       "      <td>0.073000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.203300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.118000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1460</td>\n",
       "      <td>0.236000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1470</td>\n",
       "      <td>0.256700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1480</td>\n",
       "      <td>0.232400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1490</td>\n",
       "      <td>0.225400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.084100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1510</td>\n",
       "      <td>0.389800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1520</td>\n",
       "      <td>0.194200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1530</td>\n",
       "      <td>0.250900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1540</td>\n",
       "      <td>0.090600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.245200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.188700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1570</td>\n",
       "      <td>0.229300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1580</td>\n",
       "      <td>0.131200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1590</td>\n",
       "      <td>0.335300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.134200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1610</td>\n",
       "      <td>0.094500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.208600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1630</td>\n",
       "      <td>0.309400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1640</td>\n",
       "      <td>0.183600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.209500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1660</td>\n",
       "      <td>0.055900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1670</td>\n",
       "      <td>0.162900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.203500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1690</td>\n",
       "      <td>0.124600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.121600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1710</td>\n",
       "      <td>0.162800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1720</td>\n",
       "      <td>0.176800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1730</td>\n",
       "      <td>0.135500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.230900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.138800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1760</td>\n",
       "      <td>0.231500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1770</td>\n",
       "      <td>0.083900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1780</td>\n",
       "      <td>0.264300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1790</td>\n",
       "      <td>0.195600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.207700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1810</td>\n",
       "      <td>0.151500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1820</td>\n",
       "      <td>0.168600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1830</td>\n",
       "      <td>0.179800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1840</td>\n",
       "      <td>0.217200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.236300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.145200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1870</td>\n",
       "      <td>0.190100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1880</td>\n",
       "      <td>0.173000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1890</td>\n",
       "      <td>0.122800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.187700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1910</td>\n",
       "      <td>0.308600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.131800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1930</td>\n",
       "      <td>0.183000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1940</td>\n",
       "      <td>0.275400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.230800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1960</td>\n",
       "      <td>0.138200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1970</td>\n",
       "      <td>0.209700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>0.129500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1980, training_loss=0.24691737124113122, metrics={'train_runtime': 1558.1134, 'train_samples_per_second': 10.166, 'train_steps_per_second': 1.271, 'total_flos': 2098283594711040.0, 'train_loss': 0.24691737124113122, 'epoch': 2.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "738474f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b741d1",
   "metadata": {},
   "source": [
    "### Checking the model on test data and finding the polarity of the sentiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5cd9a6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_check_result gives the output in from of 0 or 1\n",
    "# 0 being positive and 1 being negative\n",
    "\n",
    "import numpy as np\n",
    "def to_check_result(test_encoding):\n",
    "    input_ids = torch.tensor(test_encoding[\"input_ids\"]).to(device)\n",
    "    attention_mask = torch.tensor(test_encoding[\"attention_mask\"]).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids.unsqueeze(0), attention_mask.unsqueeze(0))\n",
    "    y =np.argmax(outputs[0].to('cpu').numpy())\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ebcfc511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing the test tweets and inputting them to model\n",
    "l2 = []\n",
    "for i in test['tweet']:\n",
    "    test_encoding1 = tokenizer(i, truncation = True, padding = True)\n",
    "    input_ids = torch.tensor(test_encoding1[\"input_ids\"]).to(device)\n",
    "    attention_mask = torch.tensor(test_encoding1[\"attention_mask\"]).to(device)\n",
    "    op = to_check_result(test_encoding1)\n",
    "    l2.append(op)     # list contains the output sentiment of all the tweets in the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "20134636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I hate the new #iphone upgrade. Won't let me d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>currently shitting my fucking pants. #apple #i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'd like to puts some CD-ROMS on my iPad, is t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My ipod is officially dead. I lost all my pict...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Been fighting iTunes all night! I only want th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948</th>\n",
       "      <td>#SamsungGalaxyNote7 Explodes, Burns 6-Year-Old...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949</th>\n",
       "      <td>Now Available - Hoodie. Check it out here - ht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <td>There goes a crack right across the screen. If...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>@codeofinterest as i said #Adobe big time we m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1952</th>\n",
       "      <td>Finally I got it .. thanx my father .. #Samsun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1953 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet\n",
       "0     I hate the new #iphone upgrade. Won't let me d...\n",
       "1     currently shitting my fucking pants. #apple #i...\n",
       "2     I'd like to puts some CD-ROMS on my iPad, is t...\n",
       "3     My ipod is officially dead. I lost all my pict...\n",
       "4     Been fighting iTunes all night! I only want th...\n",
       "...                                                 ...\n",
       "1948  #SamsungGalaxyNote7 Explodes, Burns 6-Year-Old...\n",
       "1949  Now Available - Hoodie. Check it out here - ht...\n",
       "1950  There goes a crack right across the screen. If...\n",
       "1951  @codeofinterest as i said #Adobe big time we m...\n",
       "1952  Finally I got it .. thanx my father .. #Samsun...\n",
       "\n",
       "[1953 rows x 1 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "94412a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
