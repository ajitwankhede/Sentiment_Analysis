{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9155a8a5",
   "metadata": {},
   "source": [
    "Dataset:\n",
    "    \n",
    "    The label ‘1’ means the tweet is discriminatory / gender and the label ‘0’ means the tweet is not racist/sexist, you intend to predict the labels on the test data provided.\n",
    "    \n",
    "    The columns present in our dataset are :\n",
    "\n",
    "    1. id: unique id of the tweet\n",
    "\n",
    "    2.label : 0 or 1 (positive and negative)\n",
    "\n",
    "    3. tweet: text of the tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb69a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installatin library\n",
    "# !pip3 install transformers\n",
    "# !pip3 install tensorflow\n",
    "# !pip3 install torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f7a308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import DistilBertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import matplotlib as plot\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064f67e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "train =pd.read_csv(\"train_2kmZucJ.csv\")\n",
    "test =pd.read_csv(\"test_oJQbWVk.csv\")\n",
    "ss =pd.read_csv(\"sample_submission_LnhVWA4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff68b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5e3c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549f0920",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2242951",
   "metadata": {},
   "source": [
    "We are only interested in the column label and tweet. Tweet being input column ‘and label is the output variable. The label contains 0 and 1 . with 0 being the positive tweet and 1 being the negative tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad2516c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping id as it is not of use\n",
    "train.drop(\"id\", axis = 1, inplace = True)\n",
    "test.drop(\"id\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271d7295",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a82ea43",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe65594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution fo positive and negative labels in the data\n",
    "\n",
    "# Plotting the distribution fro dataset\n",
    "ax = train.groupby('label').count().plot(kind = 'bar', title= \"Distribution of data\", legend = False)\n",
    "ax.set_xticklabels(['Negative','Positive'], rotation=0)\n",
    "# sorting data in list\n",
    "text, sentiment = list(train['tweet']), list(train['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea0ee6a",
   "metadata": {},
   "source": [
    "Need to convert the tweet and labels column in the form of a list so that we can input them to the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc1fcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting labels and tweet to list\n",
    "labels = train['label'].tolist()\n",
    "tweets = train['tweet'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee785ed8",
   "metadata": {},
   "source": [
    "Tokenization and Encoding of data:\n",
    "\n",
    "The tokenizer that we will be using is DistillBert tokenizer fast. DistilBertTokenizerFast is identical to BertTokenizerFast and runs end-to-end tokenization: punctuation splitting and wordpiece.\n",
    "\n",
    "The parameters that are present in DistilBertTokenizerFast are :\n",
    "\n",
    "( vocab_filedo_lower_case = Truedo_basic_tokenize = Truenever_split = Noneunk_token = ‘[UNK]’sep_token = ‘[SEP]’pad_token = ‘[PAD]’cls_token = ‘[CLS]’mask_token = ‘[MASK]’tokenize_chinese_chars = Truestrip_accents = None**kwargs )\n",
    "\n",
    "The method splits the sentences into tokens, adds the [cls] and [sep] tokens, and also matches the tokens to id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f26172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization and Encoding of data\n",
    "from transformers import DistilBertTokenizerFast\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf10fdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#padding and truncation of data\n",
    "inputs = tokenizer(tweets, padding =\"max_length\", truncation = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258d2e85",
   "metadata": {},
   "source": [
    "So in tokenizer, we will give a list of tweets as the input and will get the token ids in return that we will input in the model.\n",
    "\n",
    "Padding, Truncation, and all of the preprocessing are done in the DistillBert tokenizer itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac91b104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert our data to tensors.\n",
    "import torch\n",
    "class twitterDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68b9d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = twitterDataset(inputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00193cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(train_dataset.__getitem__(2))\n",
    "\n",
    "'''\n",
    "    The output of this is a dictionary containing 3 key-value pair\n",
    "\n",
    "    Input id’s: This contains tensors of integers where each integer represents the word from the original sentence.\n",
    "\n",
    "    Attention Mask: It is simply an array of 1’s and 0’s indicating which tokens are padding and which aren’t.\n",
    "\n",
    "    Labels: target variables\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f751364e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Building\n",
    "# model : Distillbert model\n",
    "from transformers import DistilBertForSequenceClassification\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b2fc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a434c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:1\")\n",
    "# device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d8bd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install pytorch torchvision torchaudio pytorch-cuda=11.6 -c pytorch -c nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe6f1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enalable gpu if it available\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308cae0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir ='./results',\n",
    "    num_train_epochs =2,\n",
    "    per_device_eval_batch_size =64,\n",
    "    warmup_steps = 500,\n",
    "    weight_decay = 0.01,\n",
    "    logging_dir ='./logs',\n",
    "    logging_steps = 10\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args= training_args,\n",
    "    train_dataset= train_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0668274",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738474f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b741d1",
   "metadata": {},
   "source": [
    "### Checking the model on test data and finding the polarity of the sentiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd9a6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_check_result gives the output in from of 0 or 1\n",
    "# 0 being positive and 1 being negative\n",
    "\n",
    "import numpy as np\n",
    "def to_check_result(test_encoding):\n",
    "    input_ids = torch.tensor(test_encoding[\"input_ids\"]).to(device)\n",
    "    attention_mask = torch.tensor(test_encoding[\"attention_mask\"]).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids.unsqueeze(0), attention_mask.unsqueeze(0))\n",
    "    y =np.argmax(outputs[0].to('cpu').numpy())\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcfc511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing the test tweets and inputting them to model\n",
    "l2 = []\n",
    "for i in test['tweet']:\n",
    "    test_encoding1 = tokenizer(i, truncation = True, padding = True)\n",
    "    input_ids = torch.tensor(test_encoding[\"input_ids\"]).to(device)\n",
    "    attention_mask = torch.tensor(test_encoding[\"attention_mask\"]).to(device)\n",
    "    op = to_check_result(test_encoding1)\n",
    "    l2.append(op)     # list contains the output sentiment of all the tweets in the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20134636",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
